{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Action PixelBytes: Catching Insights in Unified Multimodal Sequences\n\n## Description\n\n**Action-PixelBytes** est un modèle conçu pour générer simultanément du texte, des images, des animations pixel par pixel et des actions-états sous forme de séquences. L'objectif de ce projet est d'explorer un embedding unifié qui permet une génération multimodale cohérente, facilitant ainsi l'interaction entre différentes formes de données.\n\n## Dataset\n\nPour ce projet, nous utilisons le dataset **PixelBytes-PokemonSprites**. Contrairement à la version précédente, **PixelBytes-Pokemon**, cette version est structurée à la volée pour un format unifié. Cela signifie que les données sont préparées de manière à être directement utilisées pour l'entraînement du modèle, ce qui simplifie le processus d'embedding.\n\n## Tokenizer\n\nLe tokenizer joue un rôle dans la préparation des données pour le modèle. Voici comment il fonctionne pour chaque type de donnée :\n\n### Traitement du Texte\nLe texte est d'abord normalisé et converti en minuscules. Ensuite, il est encodé en format ASCII pour garantir que tous les caractères sont traités de manière uniforme. Cette étape permet de simplifier le texte avant de le transformer en une séquence de tokens.\n\n### Traitement des Images\nLes images, y compris les GIFs, sont traitées en plusieurs étapes. Chaque image est convertie en un espace colorimétrique LAB, qui est plus adapté à certaines analyses d'image. Ensuite, chaque frame d'une image animée est quantifiée selon une palette de couleurs prédéfinie, ce qui permet de réduire la complexité des données tout en préservant les informations essentielles.\n\n### Traitement des Actions-États\nLes actions-états sont normalisées pour assurer que toutes les valeurs sont sur la même échelle. Cela facilite la comparaison et l'analyse des états d'action. Les états sont ensuite quantifiés selon un ensemble prédéfini d'états d'action, ce qui permet au modèle de mieux comprendre les relations entre différentes actions.\n\n### Création de Séquences\nLes séquences sont créées en utilisant un contexte spatial et temporel. Cela signifie que pour chaque séquence, le modèle prend en compte non seulement l'entrée actuelle, mais aussi les entrées précédentes. Cela permet de générer des entrées de plusieurs éléments qui contiennent des informations pertinentes pour la tâche à accomplir.\n\n## État du Projet\n\nLe code est encore en cours de développement. Bien que les principales fonctionnalités du tokenizer et du traitement des données soient implémentées, des améliorations et des optimisations sont à venir. L'objectif est de rendre le modèle plus robuste et efficace pour la génération multimodale.\n\n## Prochaines Étapes\n\n- Finaliser l'architecture du modèle.\n- Implémenter l'entraînement et l'évaluation.\n- Optimiser les performances du modèle.\n- Effectuer des tests approfondis sur différents types de données multimodales.\n","metadata":{}},{"cell_type":"code","source":"#!pip install -q mamba-ssm causal-conv1d ## for GPU (Mambapy included)\n!pip install -q git+https://github.com/fabienfrfr/PixelBytes.git@main","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:15:00.432678Z","iopub.execute_input":"2024-09-10T15:15:00.433569Z","iopub.status.idle":"2024-09-10T15:16:25.146129Z","shell.execute_reply.started":"2024-09-10T15:15:00.433511Z","shell.execute_reply":"2024-09-10T15:16:25.144749Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# only in kaggle for HF\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\n# no warning msg during train\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n# our approach\nfrom pixelbytes import *","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:16:25.148167Z","iopub.execute_input":"2024-09-10T15:16:25.148520Z","iopub.status.idle":"2024-09-10T15:16:30.291013Z","shell.execute_reply.started":"2024-09-10T15:16:25.148484Z","shell.execute_reply":"2024-09-10T15:16:30.290212Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.cuda.amp import autocast, GradScaler\n\ndef count_parameters_in_k(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad) / 1000","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:16:30.292120Z","iopub.execute_input":"2024-09-10T15:16:30.292587Z","iopub.status.idle":"2024-09-10T15:16:30.297685Z","shell.execute_reply.started":"2024-09-10T15:16:30.292552Z","shell.execute_reply":"2024-09-10T15:16:30.296869Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\nhf_dataset = load_dataset(\"ffurfaro/PixelBytes-PokemonAll\")['train'].train_test_split(test_size=0.1, seed=42)\ntrain_ds, val_ds = hf_dataset['train'], hf_dataset['test']","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:16:30.299817Z","iopub.execute_input":"2024-09-10T15:16:30.300126Z","iopub.status.idle":"2024-09-10T15:16:34.030837Z","shell.execute_reply.started":"2024-09-10T15:16:30.300096Z","shell.execute_reply":"2024-09-10T15:16:34.030108Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/437 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f30b48eea3c4dd1a71360f0cbe510ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/16.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"080b530890aa45d7827b792de4d36e96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/533 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d8371f9d72649919bf8970695638801"}},"metadata":{}}]},{"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nDATA_REDUCTION = 2\ntokenizer = ActionPixelBytesTokenizer(data_slicing=DATA_REDUCTION)\n# Paramètres\nVOCAB_SIZE = tokenizer.vocab_size\nEMBED_SIZE = 128\nHIDDEN_SIZE = 512\nNUM_LAYERS = 2\nPXBY_DIM = 6 # tokenizer\nAR = True\nMODEL_TYPE = \"lstm\"\nBATCH_SIZE = 32\nEPOCHS = 100\nLEARNING_RATE = 0.001\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nACCUMULATION_STEPS = 4\nSEQ_LENGTH = 1024\nSTRIDE = 512\n\nconfig = ModelConfig(vocab_size=VOCAB_SIZE, embed_size=EMBED_SIZE, hidden_size=HIDDEN_SIZE, \n                          num_layers=NUM_LAYERS, pxby_dim=PXBY_DIM, auto_regressive=AR, model_type=MODEL_TYPE)\nconfig","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:18:49.400384Z","iopub.execute_input":"2024-09-10T15:18:49.400747Z","iopub.status.idle":"2024-09-10T15:18:49.413613Z","shell.execute_reply.started":"2024-09-10T15:18:49.400715Z","shell.execute_reply":"2024-09-10T15:18:49.412579Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"ModelConfig {\n  \"AR\": true,\n  \"d_conv\": 4,\n  \"d_state\": 512,\n  \"embed_size\": 126,\n  \"expand\": 2,\n  \"hidden_size\": 512,\n  \"num_layers\": 2,\n  \"pxby_dim\": 6,\n  \"pxby_emb\": 21,\n  \"transformers_version\": \"4.44.0\",\n  \"vocab_size\": 151\n}"},"metadata":{}}]},{"cell_type":"code","source":"# Initialisation du modèle\nmodel = aPxBySequenceModel(config).to(DEVICE)\nprint(f\"Le modèle a {count_parameters_in_k(model):.2f}k paramètres entraînables.\")\n# Parametre d'entrainement\noptimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\ncriterion = nn.CrossEntropyLoss(ignore_index=-100)\nscaler = GradScaler() if torch.cuda.is_available() else None","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:19:03.929585Z","iopub.execute_input":"2024-09-10T15:19:03.930462Z","iopub.status.idle":"2024-09-10T15:20:01.264761Z","shell.execute_reply.started":"2024-09-10T15:19:03.930421Z","shell.execute_reply":"2024-09-10T15:20:01.263728Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Le modèle a 3879.92k paramètres entraînables.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Préparation des données\ndef dataloading(ds):\n    dataset = TokenPxByDataset(ds, tokenizer, SEQ_LENGTH, STRIDE)\n    sampler = ShuffledSampler(dataset, seed=42)\n    return DataLoader(dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn, sampler=sampler)\ntrain_dataloader, val_dataloader = dataloading(train_ds), dataloading(val_ds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Entraînement\nmodel.train_model(train_dataloader, val_dataloader, optimizer, criterion, DEVICE, scaler, EPOCHS, ACCUMULATION_STEPS)","metadata":{"execution":{"iopub.status.busy":"2024-09-10T15:20:01.266596Z","iopub.execute_input":"2024-09-10T15:20:01.268192Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 107/107 [00:12<00:00,  8.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Validation Loss: 5.0196, Validation Accuracy: 0.0031\n","output_type":"stream"},{"name":"stderr","text":"Training:  29%|██▉       | 297/1030 [00:39<01:36,  7.58it/s]","output_type":"stream"}]},{"cell_type":"code","source":"import re\nfrom huggingface_hub import HfApi, create_repo, whoami\ndef push_model_to_hub(repo_name, model_dir, token, subfolder=None):\n    api = HfApi(token=token)\n    subfolder = re.sub(r'[^a-zA-Z0-9]+', '_', subfolder).strip('_').lower()\n\n    try:\n        create_repo(repo_name, token=token, repo_type=\"model\", exist_ok=True)\n        username = whoami(token=token)['name']\n        repo_id = f\"{username}/{repo_name}\"\n        print(f\"Repository '{repo_id}' created or already exists.\")\n    except Exception as e:\n        print(f\"Error creating repository: {e}\")\n        return\n    \n    api.upload_folder(\n        folder_path=model_dir,\n        repo_id=repo_id,\n        repo_type=\"model\",\n        path_in_repo=subfolder,\n        ignore_patterns=[\".*\"],  # Ignorer les fichiers cachés\n        create_pr=False  # Créer directement dans la branche principale\n    )\n    print(f\"Model pushed successfully to {repo_name}, subfolder: {subfolder}\")\n!ls","metadata":{"execution":{"iopub.status.busy":"2024-09-10T14:51:39.704626Z","iopub.execute_input":"2024-09-10T14:51:39.705465Z","iopub.status.idle":"2024-09-10T14:51:40.762427Z","shell.execute_reply.started":"2024-09-10T14:51:39.705390Z","shell.execute_reply":"2024-09-10T14:51:40.761438Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"lstm_predictive_best  lstm_predictive_last  training_metrics.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"# save model\npush_model_to_hub(\"aPixelBytes-PokemonLSTM\", \"lstm_predictive_last\", hf_token, \"lstm_predictive_last\")","metadata":{"execution":{"iopub.status.busy":"2024-09-10T14:50:58.422008Z","iopub.execute_input":"2024-09-10T14:50:58.422887Z","iopub.status.idle":"2024-09-10T14:50:59.907349Z","shell.execute_reply.started":"2024-09-10T14:50:58.422845Z","shell.execute_reply":"2024-09-10T14:50:59.906352Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Repository 'ffurfaro/aPixelBytes-PokemonLSTM' created or already exists.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/19.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdc482cdaa154e57bd5b7bb489642194"}},"metadata":{}},{"name":"stdout","text":"Model pushed successfully to aPixelBytes-PokemonLSTM, subfolder: lstm_predictive_last\n","output_type":"stream"}]},{"cell_type":"code","source":"# Test de génération\ntest_input = next(iter(dataloader))['input_ids'][:1].to(DEVICE)\ngenerated = model.generate(test_input, max_length=100)\nprint(\"Generated sequence:\", generated)","metadata":{},"execution_count":null,"outputs":[]}]}