{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PixelByte: Catching Unified Multimodal Sequence Generation\n\nCe notebook présente **PixelByte**, un modèle innovant conçu pour générer simultanément du texte et des images pixel par pixel sous forme de séquences. L'objectif est d'explorer un embedding unifié qui permet une génération multimodale cohérente.\n\n## Contexte et Architecture Proposée\n\n### Fondements Théoriques\n- **Image Transformer** : [Génération d'images pixel par pixel](https://arxiv.org/abs/1802.05751)\n- **Bi-Mamba+** : [Modèle bidirectionnel pour la prévision de séries temporelles](https://arxiv.org/abs/2404.15772)\n- **MambaByte** : [Modèle d'état d'espace sélectif sans token](https://arxiv.org/abs/2401.13660)\n\n### Concept Clé\nLe modèle PixelByte génère des séquences mixtes de texte et d'images. Il doit :\n- Gérer les transitions entre texte et image avec des sauts de ligne (ASCII 0A).\n- Maintenir la cohérence des dimensions des images générées.\n- Assimiler la tâche de \"copie\" pour reproduire des motifs complexes.\n\nCe notebook utilise la puissance des GPU T4 x2 de Kaggle pour expérimenter avec des architectures avancées et des jeux de données volumineux, afin de relever les défis de la génération multimodale unifiée.\n\n## Ressources du Projet\n\n### Dataset\nPour ce projet, nous utiliserons le dataset **PixelBytes-Pokemon**, spécialement conçu pour cette tâche de génération multimodale. Ce dataset, créé par l'auteur de ce notebook, est disponible sur Hugging Face : [PixelBytes-Pokemon](https://huggingface.co/datasets/ffurfaro/PixelBytes-Pokemon). Il contient des séquences de texte et d'images de Pokémon, encodées de manière à permettre l'entraînement de notre modèle PixelByte sur des données multimodales.\n\n### Implémentation\nL'implémentation du modèle et les scripts d'entraînement sont disponibles dans le dépôt GitHub **Mamba-Bys** : [Mamba-Bys](https://github.com/fabienfrfr/Mamba-Bys). Ce dépôt contient le code source nécessaire pour reproduire les expériences, ainsi que des instructions détaillées sur la configuration et l'utilisation du modèle PixelByte.","metadata":{}},{"cell_type":"code","source":"!pip install -q git+https://github.com/fabienfrfr/Mamba-Bys.git@main","metadata":{"execution":{"iopub.status.busy":"2024-08-22T17:00:51.453043Z","iopub.execute_input":"2024-08-22T17:00:51.453761Z","iopub.status.idle":"2024-08-22T17:01:54.962646Z","shell.execute_reply.started":"2024-08-22T17:00:51.453714Z","shell.execute_reply":"2024-08-22T17:01:54.961405Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from mamba_bys.mambabys import *\nfrom mamba_bys.train import *\nfrom mamba_bys.dataset import *\nfrom mamba_bys.tokenizer import *\n\nfrom datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-22T17:01:54.964983Z","iopub.execute_input":"2024-08-22T17:01:54.965356Z","iopub.status.idle":"2024-08-22T17:02:00.085510Z","shell.execute_reply.started":"2024-08-22T17:01:54.965282Z","shell.execute_reply":"2024-08-22T17:02:00.084728Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/mamba_ssm/ops/selective_scan_interface.py:164: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  def forward(ctx, xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,\n/opt/conda/lib/python3.10/site-packages/mamba_ssm/ops/selective_scan_interface.py:240: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n  def backward(ctx, dout):\n/opt/conda/lib/python3.10/site-packages/mamba_ssm/ops/triton/layer_norm.py:986: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  def forward(\n/opt/conda/lib/python3.10/site-packages/mamba_ssm/ops/triton/layer_norm.py:1045: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n  def backward(ctx, dout, *args):\n/opt/conda/lib/python3.10/site-packages/mamba_ssm/distributed/tensor_parallel.py:26: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  def forward(ctx, x, weight, bias, process_group=None, sequence_parallel=True):\n/opt/conda/lib/python3.10/site-packages/mamba_ssm/distributed/tensor_parallel.py:62: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n  def backward(ctx, grad_output):\n/opt/conda/lib/python3.10/site-packages/mamba_ssm/ops/triton/ssd_combined.py:758: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  def forward(ctx, zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states=None, seq_idx=None, dt_limit=(0.0, float(\"inf\")), return_final_states=False, activation=\"silu\",\n/opt/conda/lib/python3.10/site-packages/mamba_ssm/ops/triton/ssd_combined.py:836: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n  def backward(ctx, dout, *args):\n","output_type":"stream"}]},{"cell_type":"code","source":"# init\nhf_dataset = load_dataset(\"ffurfaro/PixelBytes-Pokemon\")\nds = hf_dataset[\"train\"].train_test_split(test_size=0.1)\n\ntrain_dataset = PxByDataset(ds[\"train\"][\"pixelbyte\"], seq_length=256, stride=32)\ntest_dataset = PxByDataset(ds[\"test\"][\"pixelbyte\"], seq_length=256, stride=32)\n\npixelbyte = PixelBytesTokenizer()","metadata":{"execution":{"iopub.status.busy":"2024-08-22T17:02:00.086674Z","iopub.execute_input":"2024-08-22T17:02:00.087117Z","iopub.status.idle":"2024-08-22T17:02:26.314608Z","shell.execute_reply.started":"2024-08-22T17:02:00.087084Z","shell.execute_reply":"2024-08-22T17:02:26.313609Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/426 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a88d66d1eac46d695e8f46d28bee9ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/4.59M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7616039ca03b44648cbcb1e2a5ba4d01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/964 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da101f50401d41cbac17ea91ff429206"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"vocab_size = len(pixelbyte.vocab)\nembedding_dim = 16\nhidden_dim = 64\n# choose model (simple, attention, mamba)\n#model = SimpleSeqModel(vocab_size, embedding_dim, hidden_dim)\nmodel = SimpleAttentionModel(vocab_size, embedding_dim, hidden_dim)\n# Mamba\nd_model = 64 # 256 is to hudge !\nd_state = 16\nn_layers = 8\nconfig = MambaConfig(dim=d_model, d_state=d_state, depth=n_layers, vocab_size=vocab_size)\n# import model\nmodel = BysMamba(config)","metadata":{"execution":{"iopub.status.busy":"2024-08-22T17:10:28.362362Z","iopub.execute_input":"2024-08-22T17:10:28.363210Z","iopub.status.idle":"2024-08-22T17:10:28.389852Z","shell.execute_reply.started":"2024-08-22T17:10:28.363160Z","shell.execute_reply":"2024-08-22T17:10:28.389005Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    train_dataset=train_dataset,\n    test_dataset=test_dataset,\n    batch_size=32,\n    learning_rate=0.001,\n    num_epochs=200,\n    save_dir='model_checkpoints',\n    compile_model=False, #True,\n    model_name=\"SimpleSeqModel\",\n    dataset_name=\"PixelBytes-Pokemon\",\n    eval_every=5  # Évaluer tous les 5 epochs\n)\n\n\ntrainer = Trainer(\n    model=model,\n    train_dataset=train_dataset,\n    test_dataset=test_dataset,\n    batch_size=2,\n    learning_rate=0.001,\n    num_epochs=200,\n    save_dir='model_checkpoints',\n    compile_model=False, #True,\n    model_name=\"Mambabys\",\n    dataset_name=\"PixelBytes-Pokemon\",\n    eval_every=5  # Évaluer tous les 5 epochs\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-22T17:10:32.144228Z","iopub.execute_input":"2024-08-22T17:10:32.144629Z","iopub.status.idle":"2024-08-22T17:10:32.261679Z","shell.execute_reply.started":"2024-08-22T17:10:32.144595Z","shell.execute_reply":"2024-08-22T17:10:32.260435Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Epoch 1/200:   0%|          | 0/11737 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 30\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     eval_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m  \u001b[38;5;66;03m# Évaluer tous les 5 epochs\u001b[39;00m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     16\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     17\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     18\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     eval_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m  \u001b[38;5;66;03m# Évaluer tous les 5 epochs\u001b[39;00m\n\u001b[1;32m     28\u001b[0m )\n\u001b[0;32m---> 30\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mamba_bys/train.py:63\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     61\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice), targets\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 63\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, targets)\n\u001b[1;32m     65\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mamba_bys/mambabys.py:47\u001b[0m, in \u001b[0;36mBysMamba.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_embedding(x\u001b[38;5;241m.\u001b[39mview(B\u001b[38;5;241m*\u001b[39mL, M, N))\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     46\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# (batch_size*L, embedding_dim, height, width)\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m x \u001b[38;5;241m=\u001b[39m (\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mM\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;66;03m# (B,L,D)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# bidirectional mamba input\u001b[39;00m\n\u001b[1;32m     49\u001b[0m x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_mamba(x) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_mamba(torch\u001b[38;5;241m.\u001b[39mflip(x, dims\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;241m.\u001b[39mflip([\u001b[38;5;241m1\u001b[39m]))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n","\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 256, 64]' is invalid for input of size 1073741824"],"ename":"RuntimeError","evalue":"shape '[2, 256, 64]' is invalid for input of size 1073741824","output_type":"error"}]}]}