{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PixelBytes: Catching Insights in Unified Multimodal Sequences\n\nCe notebook présente **PixelBytes**, un modèle innovant conçu pour générer simultanément du texte et des images pixel par pixel sous forme de séquences. L'objectif est d'explorer un embedding unifié qui permet une génération multimodale cohérente.\n\n## Contexte et Architecture Proposée\n\n### Fondements Théoriques\n- **Image Transformer** : [Génération d'images pixel par pixel](https://arxiv.org/abs/1802.05751)\n- **Bi-Mamba+** : [Modèle bidirectionnel pour la prévision de séries temporelles](https://arxiv.org/abs/2404.15772)\n- **MambaByte** : [Modèle d'état d'espace sélectif sans token](https://arxiv.org/abs/2401.13660)\n\n### Concept Clé\nLe modèle PixelByte génère des séquences mixtes de texte et d'images. Il doit :\n- Gérer les transitions entre texte et image avec des sauts de ligne (ASCII 0A).\n- Maintenir la cohérence des dimensions des images générées.\n- Assimiler la tâche de \"copie\" pour reproduire des motifs complexes.\n\nCe notebook utilise la puissance des GPU T4 x2 de Kaggle pour expérimenter avec des architectures avancées et des jeux de données volumineux, afin de relever les défis de la génération multimodale unifiée.\n\n## Ressources du Projet\n\n### Dataset\nPour ce projet, nous utiliserons le dataset **PixelBytes-Pokemon**, spécialement conçu pour cette tâche de génération multimodale. Ce dataset, créé par l'auteur de ce notebook, est disponible sur Hugging Face : [PixelBytes-Pokemon](https://huggingface.co/datasets/ffurfaro/PixelBytes-Pokemon). Il contient des séquences de texte et d'images de Pokémon, encodées de manière à permettre l'entraînement de notre modèle PixelByte sur des données multimodales.\n\n### Implémentation\nL'implémentation du modèle et les scripts d'entraînement sont disponibles dans le dépôt GitHub **Mamba-Bys** : [Mamba-Bys](https://github.com/fabienfrfr/Mamba-Bys). Ce dépôt contient le code source nécessaire pour reproduire les expériences, ainsi que des instructions détaillées sur la configuration et l'utilisation du modèle PixelByte.\n\n## Modele à entrainer :\n\n- 8 LSTM (bidirectionnel + 1,2,3 layers) + (p_embed + bi-2 layers)\n- 6 Mamba (bidirectionnel + 1,2,3 layers)\n- 3 Transformers (1,2,3 layers)\n\n# Pre-test\n\nAvant d'entrainer les 8 LSTM, prendre le pembed-bi-2 LSTM et tester la génération (à 40%, mais influence des répétitions de caractére et de pixel)\n\nForte chance de predire le meme pixel à la suite, et de prédire des espaces et voyelles.\n\nPour la generation, le modele génére uniquement le prochain element central. L'algorithme de génération doit reconstituer la structure 2D. Tel que : \n(T,T,\\n,T,\\n,P,P,P,\\t,P,P,P,\\n,T,T) donne \n([[0,0,0],[0,T,0],[0,0,0]],\n[[0,0,0],[T,T,0],[0,0,0]],\n[[0,0,0],[T,\\n,0],[0,0,0]],\n[[0,0,0],[\\n,T,0],[0,0,0]],\n[[0,0,0],[T,\\n,0],[0,0,0]],\n[[0,0,0],[0,P,0],[0,0,0]],\n[[0,0,0],[P,P,0],[0,0,0]],\n[[0,0,0],[P,P,0],[0,0,0]],\n[[0,0,0],[P,\\t,0],[0,0,0]],\n[[0,P,P],[0,P,0],[0,0,0]],\n[[P,P,P],[P,P,0],[0,0,0]],\n[[P,P,P],[P,P,0],[0,0,0]],\n[[P,\\t,0],[P,\\n,0],[0,0,0]],\n[[0,0,0],[0,T,0],[0,0,0]],\n[[0,0,0],[T,T,0],[0,0,0]],) avec P les pixel, \\n les saut de ligne et de modalité, et \\t, les changement de ligne de pixex de l'image et/ou les tabulations de texte.","metadata":{}},{"cell_type":"code","source":"!pip install -q git+https://github.com/fabienfrfr/PixelBytes.git@main","metadata":{"execution":{"iopub.status.busy":"2024-08-31T17:46:35.432018Z","iopub.execute_input":"2024-08-31T17:46:35.432402Z","iopub.status.idle":"2024-08-31T17:47:06.529363Z","shell.execute_reply.started":"2024-08-31T17:46:35.432355Z","shell.execute_reply":"2024-08-31T17:47:06.528190Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# only in kaggle for HF\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhf_token = user_secrets.get_secret(\"HF_TOKEN\")\n# no warning msg during train\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n# our approach\nfrom pixelbytes import *","metadata":{"execution":{"iopub.status.busy":"2024-08-31T17:47:26.922074Z","iopub.execute_input":"2024-08-31T17:47:26.922939Z","iopub.status.idle":"2024-08-31T17:47:27.031435Z","shell.execute_reply.started":"2024-08-31T17:47:26.922897Z","shell.execute_reply":"2024-08-31T17:47:27.030410Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# init\nhf_dataset = load_dataset(\"ffurfaro/PixelBytes-Pokemon\")\nds = hf_dataset[\"train\"].train_test_split(test_size=0.1)\n\n# impossible config in Kaggle --> but good way to train apparently\ntrain_dataset = PxByDataset(ds[\"train\"][\"pixelbyte\"], seq_length=128, stride=1) # 256, 32\ntest_dataset = PxByDataset(ds[\"test\"][\"pixelbyte\"], seq_length=128, stride=1)\n\npixelbyte = PixelBytesTokenizer()\nvocab_size = pixelbyte.__len__()","metadata":{"execution":{"iopub.status.busy":"2024-08-31T17:48:16.076422Z","iopub.execute_input":"2024-08-31T17:48:16.077147Z","iopub.status.idle":"2024-08-31T17:48:53.603865Z","shell.execute_reply.started":"2024-08-31T17:48:16.077104Z","shell.execute_reply":"2024-08-31T17:48:53.602628Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/426 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93c445db94ba44d38583fa38ad39a487"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/4.59M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d500f9ab444b42328a6b9fd418ac25de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/964 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32f59df2f65741db843a8a351d1dde55"}},"metadata":{}}]},{"cell_type":"code","source":"### Config LSTM\n# modele de reference (LSTM, bidirectionnel, pxby, 81 dim (9 embed), 64 state, 2 layers) (fait)\nmodel_config = ModelConfig(dim=81, d_state=64, depth=2, vocab_size=vocab_size)\n# modele LSTM (LSTM, bidirectionnel, center, 81 dim (9 embed), 64 state, 2 layers) #validateur 1 (fait)\nmodel_config = ModelConfig(dim=81, d_state=64, depth=2, vocab_size=vocab_size, pxby_embed=False, pembed=False)\n# modele LSTM (LSTM, bidirectionnel, pxby-noconv, 81 dim (9 embed), 64 state, 2 layers) #validateur 2 (fait)\nmodel_config = ModelConfig(dim=81, d_state=64, depth=2, vocab_size=vocab_size, pembed=False)\n# modele LSTM (LSTM, unidirectionnel, pxby, 81 dim (9 embed), 64 state, 2 layers) (fait)\nmodel_config = ModelConfig(dim=81, d_state=64, depth=2, vocab_size=vocab_size, bidirectional=False)\n# modele LSTM (LSTM, bidirectionnel, pxby, 36 dim (9 embed), 64 state, 2 layers) (fait)\nmodel_config = ModelConfig(dim=36, d_state=64, depth=2, vocab_size=vocab_size)\n# modele LSTM (LSTM, bidirectionnel, pxby, 162 dim (18 embed), 64 state, 2 layers) (fait)\nmodel_config = ModelConfig(dim=162, d_state=64, depth=2, vocab_size=vocab_size)\n# modele LSTM (LSTM, bidirectionnel, pxby, 81 dim (9 embed), 32 state, 2 layers) (fait)\nmodel_config = ModelConfig(dim=81, d_state=32, depth=2, vocab_size=vocab_size)\n# modele LSTM (LSTM, bidirectionnel, pxby, 81 dim (9 embed), 128 state, 2 layers) (fait)\nmodel_config = ModelConfig(dim=81, d_state=128, depth=2, vocab_size=vocab_size)\n# modele LSTM (LSTM, bidirectionnel, pxby, 81 dim (9 embed), 64 state, 1 layers) (fait)\nmodel_config = ModelConfig(dim=81, d_state=64, depth=1, vocab_size=vocab_size)\n# modele LSTM (LSTM, bidirectionnel, pxby, 81 dim (9 embed), 64 state, 3 layers) (fait)\nmodel_config = ModelConfig(dim=81, d_state=64, depth=3, vocab_size=vocab_size)\n# modele LSTM (LSTM, bidirectionnel, pxby, 81 dim (9 embed), 64 state, 2 layers) #special (fait)\nmodel_config = ModelConfig(dim=81, d_state=64, depth=2, vocab_size=vocab_size)\n\n### Model LSTM\nmodel = SimpleRNNModel(model_config)\n\n\"\"\"\n### Config Mamba\n# modele Mamba (Mamba, bidirectionnel, pxby, 81 dim (9 embed), 64 state, 2 layers)\nmodel_config = ModelConfig(dim=81, d_state=64, depth=2, vocab_size=vocab_size)\n# modele Mamba (Mamba, unidirectionnel, pxby, 81 dim (9 embed), 64 state, 2 layers)\nmodel_config = ModelConfig(dim=81, d_state=64, depth=2, vocab_size=vocab_size, bidirectional=False)\n# modele Mamba (Mamba, bidirectionnel, pxby, 81 dim (9 embed), 64 state, 1 layers)\nmodel_config = ModelConfig(dim=81, d_state=64, depth=1, vocab_size=vocab_size)\n\n### Model Mamba\n#model = bMamba(model_config)\n\n### Config Transformer\n# modele Transformer (Transformer, //, pxby, 81 dim (9 embed), 64 state, 1 layers)\nmodel_config = ModelConfig(dim=81, d_state=64, depth=1, vocab_size=vocab_size)\n# modele Transformer (Transformer, //, pxby, 81 dim (9 embed), 64 state, 2 layers)\nmodel_config = ModelConfig(dim=81, d_state=64, depth=2, vocab_size=vocab_size)\n\n### Model Transformer\nmodel = SimpleTransformerModel(model_config)\n\"\"\"\n\n## model show\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T17:49:05.627678Z","iopub.execute_input":"2024-08-31T17:49:05.628639Z","iopub.status.idle":"2024-08-31T17:49:05.661223Z","shell.execute_reply.started":"2024-08-31T17:49:05.628584Z","shell.execute_reply":"2024-08-31T17:49:05.660352Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"SimpleRNNModel(\n  (embedding): PxByEmbed(\n    (projection): Linear(in_features=81, out_features=81, bias=True)\n    (norm): LayerNorm((81,), eps=1e-05, elementwise_affine=True)\n    (linear_embedding): Embedding(113, 9)\n    (patch_embedding): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n  (_lstm): LSTM(81, 32, batch_first=True, bidirectional=True)\n  (lstm): LSTM(64, 64, batch_first=True)\n  (fc): Linear(in_features=64, out_features=113, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_config = TrainConfig(model=model, model_config=model_config, dataset_name=\"PixelBytes-Pokemon\", hf_token=hf_token,\n                           train_dataset=train_dataset,test_dataset=test_dataset, num_epochs=1000, repo_name=\"PixelBytes-Pokemon\") # 200\ntrainer = Trainer(train_config)","metadata":{"execution":{"iopub.status.busy":"2024-08-31T17:49:47.846431Z","iopub.execute_input":"2024-08-31T17:49:47.847214Z","iopub.status.idle":"2024-08-31T17:49:47.857260Z","shell.execute_reply.started":"2024-08-31T17:49:47.847168Z","shell.execute_reply":"2024-08-31T17:49:47.856354Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Complete path of pytorch model '.pth': models/rnn_bi_pxby_conv_81-dim_64-state_2-layer_PixelBytes-Pokemon\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train_and_evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-08-31T17:49:50.033788Z","iopub.execute_input":"2024-08-31T17:49:50.034630Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Training:   0%|          | 5/1000 [18:36<62:14:46, 225.21s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5: Train Loss: 1.1866, Test Loss: 1.2122, Test Acc: 63.87%\n","output_type":"stream"},{"name":"stderr","text":"Training:   1%|          | 10/1000 [37:10<61:45:43, 224.59s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10: Train Loss: 1.1537, Test Loss: 1.1869, Test Acc: 64.52%\n","output_type":"stream"},{"name":"stderr","text":"Training:   2%|▏         | 15/1000 [55:44<61:38:13, 225.27s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 15: Train Loss: 1.1389, Test Loss: 1.1640, Test Acc: 65.16%\n","output_type":"stream"},{"name":"stderr","text":"Training:   2%|▏         | 20/1000 [1:13:50<59:52:16, 219.94s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 20: Train Loss: 1.1290, Test Loss: 1.1572, Test Acc: 65.22%\n","output_type":"stream"},{"name":"stderr","text":"Training:   2%|▎         | 25/1000 [1:32:04<59:45:31, 220.65s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 25: Train Loss: 1.1218, Test Loss: 1.1542, Test Acc: 65.39%\n","output_type":"stream"},{"name":"stderr","text":"Training:   3%|▎         | 30/1000 [1:50:13<59:15:05, 219.90s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 30: Train Loss: 1.1164, Test Loss: 1.1545, Test Acc: 65.16%\n","output_type":"stream"},{"name":"stderr","text":"Training:   4%|▎         | 35/1000 [2:08:23<58:55:34, 219.83s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 35: Train Loss: 1.1117, Test Loss: 1.1459, Test Acc: 65.48%\n","output_type":"stream"},{"name":"stderr","text":"Training:   4%|▍         | 40/1000 [2:26:35<58:46:01, 220.38s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 40: Train Loss: 1.1080, Test Loss: 1.1410, Test Acc: 65.64%\n","output_type":"stream"},{"name":"stderr","text":"Training:   4%|▍         | 45/1000 [2:44:49<58:28:15, 220.41s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 45: Train Loss: 1.1050, Test Loss: 1.1407, Test Acc: 65.51%\n","output_type":"stream"},{"name":"stderr","text":"Training:   5%|▌         | 50/1000 [3:03:05<58:21:04, 221.12s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 50: Train Loss: 1.1029, Test Loss: 1.1339, Test Acc: 65.63%\n","output_type":"stream"},{"name":"stderr","text":"Training:   6%|▌         | 55/1000 [3:21:22<58:04:53, 221.26s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 55: Train Loss: 1.1006, Test Loss: 1.1345, Test Acc: 65.68%\n","output_type":"stream"},{"name":"stderr","text":"Training:   6%|▌         | 60/1000 [3:39:43<57:58:57, 222.06s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 60: Train Loss: 1.0989, Test Loss: 1.1385, Test Acc: 65.32%\n","output_type":"stream"},{"name":"stderr","text":"Training:   6%|▋         | 65/1000 [3:58:06<57:51:46, 222.79s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 65: Train Loss: 1.0971, Test Loss: 1.1380, Test Acc: 65.56%\n","output_type":"stream"},{"name":"stderr","text":"Training:   7%|▋         | 70/1000 [4:16:35<57:39:55, 223.22s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 70: Train Loss: 1.0953, Test Loss: 1.1279, Test Acc: 65.82%\n","output_type":"stream"},{"name":"stderr","text":"Training:   8%|▊         | 75/1000 [4:34:57<56:56:05, 221.58s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 75: Train Loss: 1.0938, Test Loss: 1.1308, Test Acc: 65.82%\n","output_type":"stream"},{"name":"stderr","text":"Training:   8%|▊         | 80/1000 [4:53:04<56:12:40, 219.96s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 80: Train Loss: 1.0921, Test Loss: 1.1285, Test Acc: 65.79%\n","output_type":"stream"},{"name":"stderr","text":"Training:   8%|▊         | 85/1000 [5:11:14<55:49:27, 219.64s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 85: Train Loss: 1.0906, Test Loss: 1.1245, Test Acc: 66.17%\n","output_type":"stream"},{"name":"stderr","text":"Training:   9%|▉         | 90/1000 [5:29:17<55:18:25, 218.80s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 90: Train Loss: 1.0890, Test Loss: 1.1276, Test Acc: 65.85%\n","output_type":"stream"},{"name":"stderr","text":"Training:  10%|▉         | 95/1000 [5:47:37<55:44:06, 221.71s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 95: Train Loss: 1.0879, Test Loss: 1.1205, Test Acc: 65.92%\n","output_type":"stream"},{"name":"stderr","text":"Training:  10%|█         | 100/1000 [6:05:59<55:32:16, 222.15s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 100: Train Loss: 1.0866, Test Loss: 1.1203, Test Acc: 66.12%\n","output_type":"stream"},{"name":"stderr","text":"Training:  10%|█         | 105/1000 [6:24:24<55:29:09, 223.18s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 105: Train Loss: 1.0865, Test Loss: 1.1240, Test Acc: 66.01%\n","output_type":"stream"},{"name":"stderr","text":"Training:  11%|█         | 110/1000 [6:42:53<55:16:50, 223.61s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 110: Train Loss: 1.0849, Test Loss: 1.1210, Test Acc: 66.04%\n","output_type":"stream"},{"name":"stderr","text":"Training:  12%|█▏        | 115/1000 [7:01:23<55:05:23, 224.09s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 115: Train Loss: 1.0839, Test Loss: 1.1218, Test Acc: 65.93%\n","output_type":"stream"},{"name":"stderr","text":"Training:  12%|█▏        | 120/1000 [7:19:35<54:03:13, 221.13s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 120: Train Loss: 1.0832, Test Loss: 1.1230, Test Acc: 66.00%\n","output_type":"stream"},{"name":"stderr","text":"Training:  12%|█▎        | 125/1000 [7:37:39<53:19:08, 219.37s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 125: Train Loss: 1.0824, Test Loss: 1.1186, Test Acc: 66.09%\n","output_type":"stream"},{"name":"stderr","text":"Training:  13%|█▎        | 130/1000 [7:55:51<53:11:15, 220.09s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 130: Train Loss: 1.0820, Test Loss: 1.1210, Test Acc: 66.25%\n","output_type":"stream"},{"name":"stderr","text":"Training:  14%|█▎        | 135/1000 [8:14:09<53:13:16, 221.50s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 135: Train Loss: 1.0810, Test Loss: 1.1173, Test Acc: 66.12%\n","output_type":"stream"},{"name":"stderr","text":"Training:  14%|█▍        | 140/1000 [8:32:30<53:02:42, 222.05s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 140: Train Loss: 1.0808, Test Loss: 1.1245, Test Acc: 65.87%\n","output_type":"stream"},{"name":"stderr","text":"Training:  14%|█▍        | 145/1000 [8:50:42<52:23:26, 220.59s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 145: Train Loss: 1.0801, Test Loss: 1.1155, Test Acc: 66.28%\n","output_type":"stream"},{"name":"stderr","text":"Training:  15%|█▌        | 150/1000 [9:09:02<52:28:55, 222.28s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 150: Train Loss: 1.0793, Test Loss: 1.1155, Test Acc: 66.16%\n","output_type":"stream"},{"name":"stderr","text":"Training:  16%|█▌        | 155/1000 [9:27:27<52:17:43, 222.80s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 155: Train Loss: 1.0786, Test Loss: 1.1137, Test Acc: 66.23%\n","output_type":"stream"},{"name":"stderr","text":"Training:  16%|█▌        | 160/1000 [9:45:32<51:00:31, 218.61s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 160: Train Loss: 1.0777, Test Loss: 1.1166, Test Acc: 66.18%\n","output_type":"stream"},{"name":"stderr","text":"Training:  16%|█▋        | 165/1000 [10:03:25<50:19:19, 216.96s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 165: Train Loss: 1.0772, Test Loss: 1.1119, Test Acc: 66.36%\n","output_type":"stream"},{"name":"stderr","text":"Training:  17%|█▋        | 170/1000 [10:21:26<50:17:01, 218.10s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 170: Train Loss: 1.0766, Test Loss: 1.1171, Test Acc: 66.05%\n","output_type":"stream"},{"name":"stderr","text":"Training:  18%|█▊        | 175/1000 [10:39:33<50:13:25, 219.16s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 175: Train Loss: 1.0760, Test Loss: 1.1106, Test Acc: 66.25%\n","output_type":"stream"},{"name":"stderr","text":"Training:  18%|█▊        | 180/1000 [10:57:39<49:55:45, 219.20s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 180: Train Loss: 1.0755, Test Loss: 1.1106, Test Acc: 66.38%\n","output_type":"stream"},{"name":"stderr","text":"Training:  18%|█▊        | 185/1000 [11:15:41<49:26:50, 218.42s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 185: Train Loss: 1.0748, Test Loss: 1.1111, Test Acc: 66.37%\n","output_type":"stream"},{"name":"stderr","text":"Training:  19%|█▉        | 190/1000 [11:33:38<48:53:56, 217.33s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 190: Train Loss: 1.0743, Test Loss: 1.1118, Test Acc: 66.41%\n","output_type":"stream"},{"name":"stderr","text":"Training:  20%|█▉        | 195/1000 [11:51:32<48:28:57, 216.82s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 195: Train Loss: 1.0742, Test Loss: 1.1093, Test Acc: 66.26%\n","output_type":"stream"},{"name":"stderr","text":"Training:  20%|█▉        | 196/1000 [11:55:05<48:07:42, 215.50s/it]","output_type":"stream"}]},{"cell_type":"code","source":"ls models","metadata":{"execution":{"iopub.status.busy":"2024-09-01T06:16:57.157836Z","iopub.execute_input":"2024-09-01T06:16:57.158264Z","iopub.status.idle":"2024-09-01T06:16:58.239811Z","shell.execute_reply.started":"2024-09-01T06:16:57.158208Z","shell.execute_reply":"2024-09-01T06:16:58.238739Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"ls: cannot access 'models': No such file or directory\n","output_type":"stream"}]},{"cell_type":"code","source":"model_ = bMamba.from_pretrained(\"ffurfaro/PixelBytes-Pokemon\", subfolder=\"ssm_bi_pxby_conv_81_dim_64_state_2_layer_last\")\nmodel_","metadata":{"execution":{"iopub.status.busy":"2024-08-27T21:31:34.900838Z","iopub.execute_input":"2024-08-27T21:31:34.901735Z","iopub.status.idle":"2024-08-27T21:31:35.067367Z","shell.execute_reply.started":"2024-08-27T21:31:34.901688Z","shell.execute_reply":"2024-08-27T21:31:35.066163Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"bMamba(\n  (embedding): PxByEmbed(\n    (projection): Linear(in_features=81, out_features=81, bias=True)\n    (norm): LayerNorm((81,), eps=1e-05, elementwise_affine=True)\n    (linear_embedding): Embedding(113, 9)\n    (patch_embedding): Conv2d(9, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  )\n  (_mamba): Mamba(\n    (in_proj): Linear(in_features=81, out_features=324, bias=False)\n    (conv1d): Conv1d(162, 162, kernel_size=(4,), stride=(1,), padding=(3,), groups=162)\n    (act): SiLU()\n    (x_proj): Linear(in_features=162, out_features=134, bias=False)\n    (dt_proj): Linear(in_features=6, out_features=162, bias=True)\n    (out_proj): Linear(in_features=162, out_features=81, bias=False)\n  )\n  (layers): ModuleList(\n    (0): Mamba(\n      (in_proj): Linear(in_features=81, out_features=324, bias=False)\n      (conv1d): Conv1d(162, 162, kernel_size=(4,), stride=(1,), padding=(3,), groups=162)\n      (act): SiLU()\n      (x_proj): Linear(in_features=162, out_features=134, bias=False)\n      (dt_proj): Linear(in_features=6, out_features=162, bias=True)\n      (out_proj): Linear(in_features=162, out_features=81, bias=False)\n    )\n  )\n  (norm): LayerNorm((81,), eps=1e-05, elementwise_affine=True)\n  (lm_head): Linear(in_features=81, out_features=113, bias=False)\n)"},"metadata":{}}]}]}