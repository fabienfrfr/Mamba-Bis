\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{brown2020language}
\citation{alayrac2023language}
\citation{radford2021learning,ramesh2022hierarchical}
\citation{baltrusaitis2019multimodal}
\citation{brown2020language}
\citation{parmar2018image}
\citation{oord2016conditional}
\citation{wang2024mamba}
\citation{gu2023visual,gu2023bidirectional}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Example of a PixelBytes-generated Pokémon and its description. Left: Generated pixelated image. Right: Corresponding text description. The red box indicates the model's attention window for both pixels and words. Note that the model currently exhibits some inaccuracies in image generation and occasionally invents words, highlighting areas for future improvement.}}{1}{figure.1}\protected@file@percent }
\newlabel{fig:example_generation}{{1}{1}{Example of a PixelBytes-generated Pokémon and its description. Left: Generated pixelated image. Right: Corresponding text description. The red box indicates the model's attention window for both pixels and words. Note that the model currently exhibits some inaccuracies in image generation and occasionally invents words, highlighting areas for future improvement}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{baltrusaitis2019multimodal}
\citation{vaswani2017attention}
\citation{lin2014microsoft}
\citation{richardson2007beautiful}
\citation{van2017neural}
\citation{bradski2000opencv,vanderwalt2014scikit}
\@writefile{toc}{\contentsline {section}{\numberline {2}Model Architecture}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Overview}{2}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Dataset Construction}{2}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Multimodal Embedding Algorithm}{2}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}PxByEmbed: Multimodal Embedding Algorithm}{2}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Managing Transitions}{2}{subsection.3.2}\protected@file@percent }
\citation{hochreiter1997long}
\citation{vaswani2017attention}
\citation{gu2022efficiently}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces PxByEmbed: Multimodal Embedding Algorithm (k=3) \newline  \textbf  {Input:} $V$: vocabulary size, $D$: embedding dimension \newline  \textbf  {Output:} Embedded representation $\mathbf  {E} \in \mathbb  {R}^{B \times L \times D}$ \newline  \textbf  {Note:} $\mathbf  {X}_{emb} \in \mathbb  {R}^{B \cdot L \times E_{int} \times k \times k}$, $\mathbf  {X}_{flat} \in \mathbb  {R}^{B \cdot L \times E_{int}k^2}$, $\mathbf  {X}_{proj} \in \mathbb  {R}^{B \cdot L \times D}$ }}{3}{algorithm.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Training and Evaluation}{3}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Model Architectures}{3}{subsection.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Training and validation metrics (Loss, Accuracy) for RNN, Transformer, and SSM models over 200 epochs.}}{3}{figure.2}\protected@file@percent }
\newlabel{fig:training_results}{{2}{3}{Training and validation metrics (Loss, Accuracy) for RNN, Transformer, and SSM models over 200 epochs}{figure.2}{}}
\citation{sutskever2014sequence,hamming1950error,papineni2002bleu}
\citation{papineni2002bleu}
\citation{yan2024multimodal}
\citation{schuster1997bidirectional}
\citation{gu2022efficiently}
\citation{baltrusaitis2019multimodal}
\citation{lin2014microsoft}
\bibstyle{plain}
\bibdata{references}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Generation Evaluation Metrics}{4}{subsection.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of model characteristics and performance (mean $\pm $ std)}}{4}{table.1}\protected@file@percent }
\newlabel{tab:model_comparison}{{1}{4}{Comparison of model characteristics and performance (mean $\pm $ std)}{table.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Results and Discussion}{4}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion and Future Work}{4}{section.6}\protected@file@percent }
\bibcite{alayrac2023language}{1}
\bibcite{baltrusaitis2019multimodal}{2}
\bibcite{bradski2000opencv}{3}
\bibcite{brown2020language}{4}
\bibcite{gu2022efficiently}{5}
\bibcite{gu2023bidirectional}{6}
\bibcite{gu2023visual}{7}
\bibcite{hamming1950error}{8}
\bibcite{hochreiter1997long}{9}
\bibcite{lin2014microsoft}{10}
\bibcite{papineni2002bleu}{11}
\bibcite{parmar2018image}{12}
\bibcite{radford2021learning}{13}
\bibcite{ramesh2022hierarchical}{14}
\bibcite{richardson2007beautiful}{15}
\bibcite{sutskever2014sequence}{16}
\bibcite{oord2016conditional}{17}
\bibcite{van2017neural}{18}
\bibcite{vanderwalt2014scikit}{19}
\bibcite{vaswani2017attention}{20}
\bibcite{wang2024mamba}{21}
\gdef \@abspage@last{5}
